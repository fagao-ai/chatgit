import os
from typing import ClassVar
from openai import AsyncOpenAI
from openai.types.chat.chat_completion_user_message_param import (
    ChatCompletionUserMessageParam,
)
from pydantic import BaseModel, Field

from chatgit.services.github import Github


class ChatMessageChunk(BaseModel):
    reasoning_content: str | None = Field(default=None)
    content: str | None = Field(default=None)


class ChatService:
    PROMPT: ClassVar[
        str
    ] = """æˆ‘å·²è·å¾—ä¸€ä¸ªå¼€æºé¡¹ç›®çš„READMEæ–‡æ¡£ï¼Œä½†æ— æ³•å¿«é€Ÿç†è§£å…¶æ ¸å¿ƒä»·å€¼ã€‚è¯·æ ¹æ®ä»¥ä¸‹ç»“æ„åˆ†æå¹¶è§£é‡Šè¯¥é¡¹ç›®ï¼Œè¦æ±‚ï¼š

ç”¨éæŠ€æœ¯è¯­è¨€ç¿»è¯‘æŠ€æœ¯æ¦‚å¿µ

çªå‡ºå®é™…åº”ç”¨ä»·å€¼

å¯¹æ¨¡ç³Šè¡¨è¿°è¿›è¡Œåˆç†æ€§æ¨æµ‹å¹¶æ ‡æ³¨

ç¼ºå¤±ä¿¡æ¯æ—¶ä¸»åŠ¨è¯¢é—®

è¯·æŒ‰ä»¥ä¸‹æ¡†æ¶è¾“å‡ºåˆ†ææŠ¥å‘Šï¼š

ä¸€ã€é¡¹ç›®é€Ÿè§ˆï¼ˆ30ç§’çœ‹æ‡‚ï¼‰
é¡¹ç›®æœ¬è´¨ï¼šç”¨æ¯”å–»çš„æ–¹å¼è¯´æ˜ï¼ˆä¾‹ï¼š"ç›¸å½“äºAIé¢†åŸŸçš„ç‘å£«å†›åˆ€"ï¼‰

è§£å†³ç—›ç‚¹ï¼šè§£é‡Šå®ƒè§£å†³äº†ä»€ä¹ˆç°å®é—®é¢˜

æ ¸å¿ƒèƒ½åŠ›ï¼šä¸è¶…è¿‡3ä¸ªæŠ€æœ¯å…³é”®è¯

é€‚ç”¨å¯¹è±¡ï¼šé€‚åˆå“ªäº›äºº/ä¼ä¸šä½¿ç”¨ï¼Ÿ

äºŒã€å…³é”®æŠ€æœ¯æ‹†è§£
æ¶æ„å›¾ç¤ºï¼šç”¨æ–‡å­—æè¿°ç³»ç»Ÿæ¶æ„æµå‘ï¼ˆä¾‹ï¼š"ç”¨æˆ·è¾“å…¥â†’äº‘ç«¯å¤„ç†â†’æ™ºèƒ½åˆ†å‘â†’ç»“æœå¯è§†åŒ–"ï¼‰

åˆ›æ–°ç‚¹åˆ†æï¼šå¯¹æ¯”ä¼ ç»Ÿæ–¹æ¡ˆçš„æ”¹è¿›ï¼ˆåˆ—è¡¨å‘ˆç°ï¼‰

æŠ€æœ¯ä¾èµ–ï¼šå¿…é¡»çš„åŸºç¡€è®¾æ–½/å·¥å…·é“¾

ä¸‰ã€å®ç”¨ä»·å€¼è¯„ä¼°
æ•ˆç‡æå‡ï¼šé¢„è®¡å¯èŠ‚çœçš„æ—¶é—´/èµ„æºæ¯”ä¾‹

æˆæœ¬ä¼˜åŠ¿ï¼šä¸ä¼ ç»Ÿæ–¹æ¡ˆçš„è´¢åŠ¡å¯¹æ¯”

é£é™©æç¤ºï¼šéƒ¨ç½²æ—¶éœ€æ³¨æ„çš„æŠ€æœ¯å€º/å…¼å®¹æ€§é—®é¢˜

å››ã€ä¸Šæ‰‹å®æ“æŒ‡å¼•
ç¯å¢ƒå‡†å¤‡æ¸…å•ï¼šåˆ†æ“ä½œç³»ç»Ÿè¯´æ˜ä¾èµ–é¡¹

é…ç½®é¿å‘æŒ‡å—ï¼šå¸¸è§å®‰è£…é”™è¯¯çš„é¢„é˜²æªæ–½

åœºæ™¯åŒ–ç”¨ä¾‹ï¼ˆè‡³å°‘2ä¸ªï¼‰ï¼š

åŸºç¡€ç”¨ä¾‹ï¼šå°ç™½ç”¨æˆ·æ“ä½œè·¯å¾„

é«˜çº§ç”¨ä¾‹ï¼šå¼€å‘è€…å®šåˆ¶æ–¹æ¡ˆ

äº”ã€æ·±åº¦è¿½é—®å»ºè®®
éœ€è¡¥å……çš„æŠ€æœ¯ç»†èŠ‚ï¼š______

åº”éªŒè¯çš„æ€§èƒ½æŒ‡æ ‡ï¼š______

æ¨èå»¶ä¼¸å­¦ä¹ èµ„æ–™ï¼š______

è¯·ç›´æ¥æä¾›é¡¹ç›®READMEå†…å®¹ï¼Œæˆ‘å°†æŒ‰æ­¤æ¡†æ¶ç”Ÿæˆè§£è¯»æŠ¥å‘Šï¼Œå¹¶ç”¨ğŸ› ï¸/âš ï¸/ğŸ’¡ç¬¦å·æ ‡æ³¨æŠ€æœ¯éš¾ç‚¹ã€é£é™©ç‚¹å’Œåˆ›æ–°ç‚¹ã€‚
ç¤ºä¾‹æ®µè½ï¼ˆä¾›å‚è€ƒï¼‰ï¼š
ğŸ’¡ åˆ›æ–°ç‚¹åˆ†æ
ä¼ ç»Ÿæ–¹æ¡ˆéœ€æ‰‹åŠ¨æ ‡æ³¨æ•°æ®ï¼ˆè€—æ—¶2-3å¤©/é¡¹ç›®ï¼‰ï¼Œæœ¬é¡¹ç›®é€šè¿‡____æŠ€æœ¯å®ç°è‡ªåŠ¨æ ‡æ³¨ï¼Œå‡†ç¡®ç‡æå‡40%çš„åŒæ—¶ï¼Œå¤„ç†é€Ÿåº¦è¾¾åˆ°æ¯ç§’300å¸§ï¼Œç›¸å½“äºäººå·¥æ•ˆç‡çš„50å€ã€‚

âš ï¸ é£é™©æç¤º
å½“å‰ç‰ˆæœ¬åœ¨Windowsç¯å¢ƒä¸‹çš„____æ¨¡å—å­˜åœ¨å†…å­˜æ³„æ¼é£é™©ï¼Œè¿ç»­è¿è¡Œè¶…è¿‡48å°æ—¶éœ€é‡å¯æœåŠ¡ï¼ˆè¯¦è§Issues #23ï¼‰

ä»“åº“READMEå†…å®¹ï¼š
{readme}
"""

    def __init__(
        self,
        *,
        model: str | None = None,
        api_key: str | None = None,
        base_url: str | None = None,
        timeout: int = 600,
    ):
        if api_key is None:
            api_key = os.environ.get("OPENAI_API_KEY")
        if base_url is None:
            base_url = os.environ.get("OPENAI_BASE_URL")
        if model is None:
            model = os.environ.get("OPENAI_MODEL")
        self.client = AsyncOpenAI(
            api_key=api_key, base_url=base_url, timeout=timeout, max_retries=3
        )
        self.model = model

    async def chat(self, messages: list[ChatCompletionUserMessageParam]):
        response = await self.client.chat.completions.create(
            model=self.model, messages=messages, stream=True
        )
        async for chunk in response:
            if not chunk.choices:
                continue
            if hasattr(chunk.choices[0].delta, "reasoning_content"):  # type: ignore
                yield ChatMessageChunk(
                    reasoning_content=chunk.choices[0].delta.reasoning_content
                )  # type: ignore
            else:
                yield ChatMessageChunk(
                    content=chunk.choices[0].delta.content, reasoning_content=None
                )  # type: ignore

    async def repo_chat(self, repo_url: str, github_token: str | None = None):
        readme = await Github(token=github_token).get_readme(repo_url)
        messages: list[ChatCompletionUserMessageParam] = [
            {"role": "user", "content": self.PROMPT.format(readme=readme)}
        ]
        async for item in self.chat(messages):
            yield item

    async def get_title(
        self, repo: str, messages: list[ChatCompletionUserMessageParam]
    ):
        prompt = """åŸºäºå¯¹è¯å†å²,ç”Ÿæˆ3-5å­—çš„æ ‡é¢˜,è¦æ±‚:
1. ç›´å‡»é¡¹ç›®æ ¸å¿ƒåŠŸèƒ½/æœ€å¤§äº®ç‚¹  
2. å¼€å¤´æˆ–ç»“å°¾åŠ 1ä¸ªç²¾å‡†åŒ¹é…emoji  
3. ç¦ç”¨æ€»ç»“/åˆ†æç­‰é™„åŠ å†…å®¹  
4. è¾“å‡ºä»…ä¿ç•™æœ€ç»ˆæ ‡é¢˜  
5. ä½¿ç”¨ç»™å®šå¯¹è¯å†å²çš„è¯­è¨€
6. ç»“åˆé¡¹ç›®åç§°: {repo}

å¦‚: é¡¹ç›®åç§°ä¸ºruff
æ ‡é¢˜: ruff: âš¡ï¸è¶…å¿«ä»£ç æ£€æŸ¥

å¯¹è¯å†å²:
{memory}
"""
        messages[
            0
        ].content = (
            f"è¯·åŸºäºè¯¥é¡¹ç›®çš„readmeä»‹ç»ä¸€ä¸‹è¯¥é¡¹ç›®çš„ä¼˜åŠ¿, ä»“åº“åœ°å€: {messages[0].content}"
        )
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "user",
                    "content": prompt.format(
                        repo=repo, memory="\n".join((msg.content for msg in messages))
                    ),
                }
            ],
            stream=False,
        )
        return response.choices[0].message.content
